# -*- coding: utf-8 -*-
"""T2S chatbot

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bE29IQlMakrWzV6wZ13w3ZJYNyyhClWK

‚úÖ STEP 1: Install Required Packages


---
"""

!pip install -U \
  torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 \
  transformers langchain langchain-community huggingface-hub \
  pandas==2.2.2 gradio matplotlib plotly accelerate bitsandbytes \
  xformers sqlite-utils --quiet

"""‚úÖ STEP 2: Import Libraries"""

import gradio as gr
import pandas as pd
import plotly.express as px
import matplotlib.pyplot as plt
import sqlite3
import re
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from langchain.llms import HuggingFacePipeline
import torch

"""‚úÖ STEP 3: Load CPU-Friendly Text2SQL Model (mrm8488/t5-base-finetuned-wikiSQL)"""

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline
from langchain_community.llms import HuggingFacePipeline

# ‚úÖ Public, lightweight Text2SQL model
model_id = "mrm8488/t5-base-finetuned-wikiSQL"

# Load model and tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForSeq2SeqLM.from_pretrained(model_id)

# Corrected generation pipeline
pipe = pipeline(
    "text2text-generation",
    model=model,
    tokenizer=tokenizer,
    max_new_tokens=128,
    do_sample=False,
    device="cpu"
)

llm = HuggingFacePipeline(pipeline=pipe)
print("‚úÖ Loaded model: mrm8488/t5-base-finetuned-wikiSQL (CPU-friendly, public)")

"""‚úÖ STEP 4: Input data cleanup"""

def clean_sql_output(raw_output):
    if not raw_output:
        return ""

    sql = raw_output

    # Replace common placeholder/table names
    sql = sql.replace("FROM table", "FROM data")

    # Handle "Top N" queries (e.g. "SELECT Top 3 Department")
    top_match = re.search(r"SELECT\s+Top\s+(\d+)\s+(\w+)", sql, re.IGNORECASE)
    if top_match:
        n = top_match.group(1)
        col = top_match.group(2)
        sql = f"SELECT {col} FROM data ORDER BY Spend DESC LIMIT {n}"

    # Remove invalid fragments
    sql = sql.replace("###", "")

    # Fix missing parentheses in aggregations
    sql = re.sub(r'\b(SUM|COUNT|AVG|MAX|MIN)\s+(\w+)', r'\1(\2)', sql, flags=re.IGNORECASE)

    # Fix missing quotes for months like Jan
    sql = re.sub(r"Month\s*=\s*jan", "LOWER(Month) = 'jan'", sql, flags=re.IGNORECASE)

    # Capitalize SQL keywords
    for keyword in ["select", "from", "where", "order by", "limit"]:
        sql = re.sub(rf"\b{keyword}\b", keyword.upper(), sql, flags=re.IGNORECASE)

    return sql.strip()

"""‚úÖ STEP 5: Query Handler Function"""

def handle_query(data_file, schema_file, question, chart_type):
    logs = "üìÅ Reading CSV...\n"
    result_text = ""

    try:
        df = pd.read_csv(data_file.name)
        logs += f"‚úÖ Loaded {df.shape[0]} rows, {df.shape[1]} columns\n"

        # Load schema if provided
        if schema_file is not None:
            schema_df = pd.read_csv(schema_file.name)
            column_names = schema_df.columns.tolist()
            logs += f"\nüìò Using schema columns from uploaded file: {column_names}\n"
        else:
            column_names = df.columns.tolist()
            logs += f"\nüìò Using schema inferred from data: {column_names}\n"

        # Build SQLite table
        logs += "\nüß† Building SQLite schema...\n"
        conn = sqlite3.connect(":memory:")
        df.to_sql("data", conn, index=False)

        # Compose prompt
        col_string = ", ".join(column_names)
        prompt = f"""### Table schema:
{col_string}

### Question:
translate English to SQL: {question}

### SQL:"""
        logs += f"\n‚úèÔ∏è Prompt:\n{prompt}\n"

        # Get model response
        model_output = llm(prompt)
        if isinstance(model_output, list):
            model_output = model_output[0]["generated_text"]

        logs += f"\nüß† Raw Model Output:\n{model_output}\n"

        # Basic SQL clean-up
        sql_query = model_output.strip()

        # Fix common issues in generated SQL
        sql_query = sql_query.replace("FROM table", "FROM data")
        sql_query = re.sub(r"SUM\s+(\w+)", r"SUM(\1)", sql_query, flags=re.IGNORECASE)
        sql_query = re.sub(r"COUNT\s+(\w+)", r"COUNT(\1)", sql_query, flags=re.IGNORECASE)

        # Add quotes to values in WHERE clause if missing (basic fix)
        sql_query = re.sub(r"= (\w+)", r"= '\1'", sql_query)

        # Fix Month column to be case-insensitive
        sql_query = sql_query.replace("Month =", "LOWER(Month) =")

        logs += f"\nüìÑ Parsed SQL:\n{sql_query}\n"
        logs += "\nüìä Executing SQL...\n"

        result_df = pd.read_sql_query(sql_query, conn)
        result_text = result_df.to_string(index=False)
        logs += f"\nüìä Result:\n{result_text}\n"
        logs += "\n‚úÖ Done.\n"

    except Exception as e:
        logs += f"\nüí• Exception:\n{str(e)}"
        result_text = "Error: " + str(e)

    return result_text, logs

"""‚úÖ STEP 6: Launch Gradio UI"""

with gr.Blocks() as demo:
    gr.Markdown("### üß† Text2SQL Chatbot with Logs + Result")

    with gr.Row():
        data_file = gr.File(label="Upload Data CSV")
        schema_file = gr.File(label="Upload Schema CSV (optional)")

    question = gr.Textbox(label="Ask your question")
    chart_type = gr.Radio(["table", "bar", "line", "pie"], value="table", label="Chart Type")

    run_btn = gr.Button("Run")

    result_text = gr.Textbox(label="Query Result", lines=5, interactive=False)
    logs_output = gr.Textbox(label="Logs", lines=20, interactive=False)

    run_btn.click(
        fn=handle_query,  # ‚úÖ Must take 4 inputs
        inputs=[data_file, schema_file, question, chart_type],
        outputs=[result_text, logs_output]
    )

demo.launch(share=True, debug=True)